{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\misso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\misso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This line creates a Dense layer with 100 neurons.\n",
    "# It doesn't specify an input shape, meaning it can \n",
    "# receive any input shape as long as the last dimension \n",
    "# reflects the number of features (unknown in this case).\n",
    "layer = tf.keras.layers.Dense(100)\n",
    "# This line creates another Dense layer with 10 neurons.\n",
    "# This time, it explicitly specifies the input shape as (None, 5).\n",
    "# None indicates the batch size can vary.\n",
    "# 5 indicates the input must have 5 features in its last dimension.\n",
    "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(None, 5):This means the layer expects input tensors with any batch size (None) and 5 features in the last dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To use a layer, simply call it.\n",
    "layer(tf.zeros([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       " array([[-0.0434404 , -0.53541714,  0.34415454, -0.4460123 , -0.36376977,\n",
       "         -0.06235719, -0.57802457, -0.6229897 , -0.26414382, -0.5380404 ],\n",
       "        [-0.26569697,  0.35765678,  0.34695196, -0.6214969 ,  0.41504806,\n",
       "          0.4532482 , -0.01825029, -0.41375244, -0.5011643 , -0.02379256],\n",
       "        [-0.19553131, -0.46126896, -0.14279959, -0.5574102 ,  0.35426027,\n",
       "          0.15109932,  0.17279696, -0.5446816 ,  0.19286114,  0.4783172 ],\n",
       "        [ 0.3710732 ,  0.35513288,  0.23010528,  0.02069855,  0.4579851 ,\n",
       "         -0.5703467 ,  0.18097109,  0.14266962, -0.27272254,  0.25204813],\n",
       "        [-0.46464032,  0.15646714,  0.07947612, -0.31822678, -0.00378495,\n",
       "          0.23303318, -0.124753  ,  0.23110938,  0.25322384,  0.06020439]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  refers to the trainable variables associated with the Dense layer you defined. \n",
    "# These variables are the weights and \n",
    "# biases that the layer learns during training to map its input to its output.\n",
    "layer.variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       " array([[-0.0434404 , -0.53541714,  0.34415454, -0.4460123 , -0.36376977,\n",
       "         -0.06235719, -0.57802457, -0.6229897 , -0.26414382, -0.5380404 ],\n",
       "        [-0.26569697,  0.35765678,  0.34695196, -0.6214969 ,  0.41504806,\n",
       "          0.4532482 , -0.01825029, -0.41375244, -0.5011643 , -0.02379256],\n",
       "        [-0.19553131, -0.46126896, -0.14279959, -0.5574102 ,  0.35426027,\n",
       "          0.15109932,  0.17279696, -0.5446816 ,  0.19286114,  0.4783172 ],\n",
       "        [ 0.3710732 ,  0.35513288,  0.23010528,  0.02069855,  0.4579851 ,\n",
       "         -0.5703467 ,  0.18097109,  0.14266962, -0.27272254,  0.25204813],\n",
       "        [-0.46464032,  0.15646714,  0.07947612, -0.31822678, -0.00378495,\n",
       "          0.23303318, -0.124753  ,  0.23110938,  0.25322384,  0.06020439]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.kernel, layer.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_outputs):\n",
    "    super(MyDenseLayer, self).__init__()\n",
    "    # the number of neurons in this custom Dense layer\n",
    "    self.num_outputs = num_outputs\n",
    "\n",
    "  # It's called during the model build phase to create trainable variables \n",
    "  # (weights and biases) for the layer based on the input shape it receives.\n",
    "  def build(self, input_shape):\n",
    "    # creates a trainable weight matrix named kernel\n",
    "    # \n",
    "    self.kernel = self.add_weight(\"kernel\",\n",
    "                                  shape=[int(input_shape[-1]), # last dimension of the input shape\n",
    "                                         self.num_outputs])\n",
    "  # Forward\n",
    "  def call(self, inputs):\n",
    "    # performs matrix multiplication between the input and \n",
    "    # the weight matrix (kernel) to produce the output.\n",
    "    return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "layer = MyDenseLayer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\misso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "[[-0.06624338 -0.6830077  -0.12006319  0.17663945 -0.2269658   0.29198703\n",
      "  -0.27604198 -0.5744072  -0.1723164  -0.43104485]\n",
      " [-0.12092712 -0.39491507 -0.01560635  0.01157218 -0.089439   -0.05295243\n",
      "  -0.06646307 -0.43210632 -0.16559185 -0.33649725]\n",
      " [ 0.10992171 -0.8105143  -0.3752871   0.18966271 -0.15153775 -0.3845326\n",
      "   0.48044533 -0.43506896 -0.71579933 -0.40534148]\n",
      " [ 0.09723689 -0.42628223 -0.4318757   0.11764948 -0.3896391  -0.3078237\n",
      "   0.24957472  0.04947088 -0.3371947  -0.12522113]\n",
      " [ 0.05393583 -0.627409   -0.61968523  0.20036758 -0.4547115  -0.6969608\n",
      "   0.7152791  -0.06261729 -0.6786833  -0.30145714]]\n"
     ]
    }
   ],
   "source": [
    "# Define some sample data\n",
    "inputs = tf.random.uniform([32, 5])  # Batch size 32, 5 features\n",
    "\n",
    "# Create your custom layer\n",
    "layer = MyDenseLayer(10)\n",
    "\n",
    "# Build a model using your custom layer\n",
    "model = tf.keras.Sequential([layer])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "# Make predictions on the sample data\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Print the first few predictions\n",
    "print(predictions[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters):\n",
    "    super(ResnetIdentityBlock, self).__init__(name='')\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "  # Creates three convolutional layers (conv2a, conv2b, conv2c) \n",
    "  # with different filter sizes and a 1x1 kernel size for the first\n",
    "  # and last layers.\n",
    "  # Adds batch normalization layers (bn2a, bn2b, bn2c) after \n",
    "  # each convolutional layer for normalization and regularization.\n",
    "    \n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x += input_tensor\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
